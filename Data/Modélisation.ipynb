{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_df_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Dataset d'entraînement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "df.podium = df.podium.map(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "train = df[df.season<2020]\n",
    "X_train = train.drop(['driver', 'podium'], axis = 1)\n",
    "y_train = train.podium\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_dict ={'model':[],\n",
    "                  'params': [],\n",
    "                  'score': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_classification(model):\n",
    "    score = 0\n",
    "    for circuit in df[df.season == 2020]['round'].unique():\n",
    "\n",
    "        test = df[(df.season == 2020) & (df['round'] == circuit)]\n",
    "        X_test = test.drop(['driver', 'podium'], axis = 1)\n",
    "        y_test = test.podium\n",
    "\n",
    "        #scaling\n",
    "        X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "\n",
    "        # make predictions\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['proba_0', 'proba_1'])\n",
    "        prediction_df['actual'] = y_test.reset_index(drop = True)\n",
    "        prediction_df.sort_values('proba_1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)\n",
    "        prediction_df['predicted'] = prediction_df.index\n",
    "        prediction_df['predicted'] = prediction_df.predicted.map(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "        score += precision_score(prediction_df.actual, prediction_df.predicted)\n",
    "\n",
    "    model_score = score / df[df.season == 2020]['round'].unique().max()\n",
    "    return model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assez lent à faire tourner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'gamma': np.logspace(-4, -1, 20),\n",
    "        'C': np.logspace(-2, 1, 20),\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']} \n",
    "\n",
    "for gamma in params['gamma']:\n",
    "    for c in params['C']:\n",
    "        for kernel in params['kernel']:\n",
    "            model_params = (gamma, c, kernel)\n",
    "            model = svm.SVC(probability = True, gamma = gamma, C = c, kernel = kernel )\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            model_score = score_classification(model)\n",
    "            \n",
    "            comparison_dict['model'].append('svm_classifier')\n",
    "            comparison_dict['params'].append(model_params)\n",
    "            comparison_dict['score'].append(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "# Le score maximal est \n",
    "print(max(comparison_dict[\"score\"]))\n",
    " \n",
    "## En déduire les paramétres correspondant au score optimal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but sera de tester plusieurs combinaison de variable explicative et choisir celle qui permettra d'avoir le meilleur \n",
    "score. On prendra comme critère (comme score) le pourcentage de course correctement prédites en 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la fonction score: \n",
    "\n",
    "def score_regression(model,xvar):\n",
    "    score=0\n",
    "    les_circuits=df[df['season']==2020][\"round\"].unique()\n",
    "    for circuit in les_circuits:\n",
    "        test=df[(df['season']==2020) & (df['round']==circuit)]\n",
    "        X_test=test[xvar]\n",
    "        y_test=test[\"podium\"]\n",
    "        \n",
    "        X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "        \n",
    "        #On fait les prédictions\n",
    "        \n",
    "        prediction_df = pd.DataFrame(model.predict(X_test), columns = ['results'])\n",
    "        prediction_df['podium'] = y_test.reset_index(drop = True)\n",
    "        prediction_df['actual'] = prediction_df['podium'].map(lambda x: 1 if x == 1 else 0)\n",
    "        prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)\n",
    "        prediction_df['predicted'] = prediction_df.index\n",
    "        prediction_df['predicted'] = prediction_df.predicted.map(lambda x: 1 if x == 0 else 0)\n",
    "        \n",
    "        score += precision_score(prediction_df['actual'],prediction_df['predicted'])\n",
    "    \n",
    "    model_score = score / df[df.season == 2020]['round'].unique().max()\n",
    "    return model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Régression linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but sera de tester plusieurs combinaison de variable explicative et choisir celle qui permettra d'avoir le meilleur \n",
    "score. On prendra comme critère (comme score) le pourcentage de course correctement prédites en 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvar_total=df.columns.drop([\"driver\",'podium'])\n",
    "xvar_random=[]\n",
    "xvar_comparison={'xvar':[],'score':[]}\n",
    "\n",
    "for i in range(10):\n",
    "    xvar_random.append(random.choices(xvar_total,k=10))\n",
    "    \n",
    "for xvar in xvar_random:\n",
    "    X_train_2 = train[xvar]\n",
    "    y_train_2 = train[\"podium\"]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = pd.DataFrame(scaler.fit_transform(X_train_2), columns = X_train_2.columns)\n",
    "    \n",
    "    model = LinearRegression(fit_intercept = 'True')\n",
    "    model.fit(X_train_2, y_train_2)\n",
    "    \n",
    "    model_score=score_regression(model,xvar)\n",
    "    \n",
    "    \n",
    "    xvar_comparison['xvar'].append(xvar)\n",
    "    xvar_comparison['score'].append(model_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut faire notre regression en prenant en compte toutes les features (Cependant il y en a surement certaines dont on aura pas la valeur avant la course pour la prédiction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept = 'True')\n",
    "model.fit(X_train, y_train)\n",
    "model_score=score_regression(model,train.columns.drop([\"driver\",\"podium\"])\n",
    "comparison_dict['model'].append('regression_lineaire')\n",
    "comparison_dict['params'].append('True')\n",
    "comparison_dict['score'].append(model_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
