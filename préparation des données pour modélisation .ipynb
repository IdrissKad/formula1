{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c61da45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (2.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from requests) (2.0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf1eced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (4.6.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c359dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (4.1.0)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from selenium) (0.19.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: sniffio in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Requirement already satisfied: idna in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: outcome in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.3.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
      "Requirement already satisfied: certifi in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from urllib3[secure]~=1.26->selenium) (3.4.7)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from urllib3[secure]~=1.26->selenium) (20.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.20)\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.16.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/hurtadoemmanuel/opt/anaconda3/lib/python3.8/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf25a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set(rc={'figure.figsize':(20,10)})\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ad09559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b42856b",
   "metadata": {},
   "source": [
    "## Importation des bases de donn√©es "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b6fe9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "races = {'season': [],\n",
    "        'round': [],\n",
    "        'circuit_id': [],\n",
    "        'lat': [],\n",
    "        'long': [],\n",
    "        'country': [],\n",
    "        'date': [],\n",
    "        'url': []}\n",
    "\n",
    "for year in list(range(1990,2021)):\n",
    "    \n",
    "    url = 'https://ergast.com/api/f1/{}.json'\n",
    "    r = requests.get(url.format(year))\n",
    "    json = r.json()\n",
    "\n",
    "    for item in json['MRData']['RaceTable']['Races']:\n",
    "        try:\n",
    "            races['season'].append(int(item['season']))\n",
    "        except:\n",
    "            races['season'].append(None)\n",
    "\n",
    "        try:\n",
    "            races['round'].append(int(item['round']))\n",
    "        except:\n",
    "            races['round'].append(None)\n",
    "\n",
    "        try:\n",
    "            races['circuit_id'].append(item['Circuit']['circuitId'])\n",
    "        except:\n",
    "            races['circuit_id'].append(None)\n",
    "\n",
    "        try:\n",
    "            races['lat'].append(float(item['Circuit']['Location']['lat']))\n",
    "        except:\n",
    "            races['lat'].append(None)\n",
    "\n",
    "        try:\n",
    "            races['long'].append(float(item['Circuit']['Location']['long']))\n",
    "        except:\n",
    "            races['long'].append(None)\n",
    "\n",
    "        try:\n",
    "            races['country'].append(item['Circuit']['Location']['country'])\n",
    "        except:\n",
    "            races['country'].append(None)\n",
    "\n",
    "        try:\n",
    "            races['date'].append(item['date'])\n",
    "        except:\n",
    "            races['date'].append(None)\n",
    "\n",
    "        try:\n",
    "            races['url'].append(item['url'])\n",
    "        except:\n",
    "            races['url'].append(None)\n",
    "        \n",
    "race= pd.DataFrame(races)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "242ee491",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = []\n",
    "for year in np.array(race.season.unique()):\n",
    "    rounds.append([year, list(race[race.season == year]['round'])])\n",
    "\n",
    "# query API\n",
    "    \n",
    "results = {'season': [],\n",
    "          'round':[],\n",
    "           'circuit_id':[],\n",
    "          'driver': [],\n",
    "           'date_of_birth': [],\n",
    "           'nationality': [],\n",
    "          'constructor': [],\n",
    "          'grid': [],\n",
    "          'time': [],\n",
    "          'status': [],\n",
    "          'points': [],\n",
    "          'podium': []}\n",
    "\n",
    "for n in list(range(len(rounds))):\n",
    "    for i in rounds[n][1]:\n",
    "    \n",
    "        url = 'http://ergast.com/api/f1/{}/{}/results.json'\n",
    "        r = requests.get(url.format(rounds[n][0], i))\n",
    "        json = r.json()\n",
    "\n",
    "        for item in json['MRData']['RaceTable']['Races'][0]['Results']:\n",
    "            try:\n",
    "                results['season'].append(int(json['MRData']['RaceTable']['Races'][0]['season']))\n",
    "            except:\n",
    "                results['season'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['round'].append(int(json['MRData']['RaceTable']['Races'][0]['round']))\n",
    "            except:\n",
    "                results['round'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['circuit_id'].append(json['MRData']['RaceTable']['Races'][0]['Circuit']['circuitId'])\n",
    "            except:\n",
    "                results['circuit_id'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['driver'].append(item['Driver']['driverId'])\n",
    "            except:\n",
    "                results['driver'].append(None)\n",
    "            \n",
    "            try:\n",
    "                results['date_of_birth'].append(item['Driver']['dateOfBirth'])\n",
    "            except:\n",
    "                results['date_of_birth'].append(None)\n",
    "                \n",
    "            try:\n",
    "                results['nationality'].append(item['Driver']['nationality'])\n",
    "            except:\n",
    "                results['nationality'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['constructor'].append(item['Constructor']['constructorId'])\n",
    "            except:\n",
    "                results['constructor'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['grid'].append(int(item['grid']))\n",
    "            except:\n",
    "                results['grid'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['time'].append(int(item['Time']['millis']))\n",
    "            except:\n",
    "                results['time'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['status'].append(item['status'])\n",
    "            except:\n",
    "                results['status'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['points'].append(int(item['points']))\n",
    "            except:\n",
    "                results['points'].append(None)\n",
    "\n",
    "            try:\n",
    "                results['podium'].append(int(item['position']))\n",
    "            except:\n",
    "                results['podium'].append(None)\n",
    "\n",
    "           \n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cba3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_standings = {'season': [],\n",
    "                    'round':[],\n",
    "                    'driver': [],\n",
    "                    'driver_points': [],\n",
    "                    'driver_wins': [],\n",
    "                   'driver_standings_pos': []}\n",
    "\n",
    "# query API\n",
    "\n",
    "for n in list(range(len(rounds))):     \n",
    "    for i in rounds[n][1]:    # iterate through rounds of each year\n",
    "    \n",
    "        url = 'https://ergast.com/api/f1/{}/{}/driverStandings.json'\n",
    "        r = requests.get(url.format(rounds[n][0], i))\n",
    "        json = r.json()\n",
    "\n",
    "        for item in json['MRData']['StandingsTable']['StandingsLists'][0]['DriverStandings']:\n",
    "            try:\n",
    "                driver_standings['season'].append(int(json['MRData']['StandingsTable']['StandingsLists'][0]['season']))\n",
    "            except:\n",
    "                driver_standings['season'].append(None)\n",
    "\n",
    "            try:\n",
    "                driver_standings['round'].append(int(json['MRData']['StandingsTable']['StandingsLists'][0]['round']))\n",
    "            except:\n",
    "                driver_standings['round'].append(None)\n",
    "                                         \n",
    "            try:\n",
    "                driver_standings['driver'].append(item['Driver']['driverId'])\n",
    "            except:\n",
    "                driver_standings['driver'].append(None)\n",
    "            \n",
    "            try:\n",
    "                driver_standings['driver_points'].append(int(item['points']))\n",
    "            except:\n",
    "                driver_standings['driver_points'].append(None)\n",
    "            \n",
    "            try:\n",
    "                driver_standings['driver_wins'].append(int(item['wins']))\n",
    "            except:\n",
    "                driver_standings['driver_wins'].append(None)\n",
    "                \n",
    "            try:\n",
    "                driver_standings['driver_standings_pos'].append(int(item['position']))\n",
    "            except:\n",
    "                driver_standings['driver_standings_pos'].append(None)\n",
    "            \n",
    "driver_standings = pd.DataFrame(driver_standings)\n",
    "\n",
    "# define lookup function to shift points and number of wins from previous rounds\n",
    "\n",
    "def lookup (df, team, points):\n",
    "    df['lookup1'] = df.season.astype(str) + df[team] + df['round'].astype(str)\n",
    "    df['lookup2'] = df.season.astype(str) + df[team] + (df['round']-1).astype(str)\n",
    "    new_df = df.merge(df[['lookup1', points]], how = 'left', left_on='lookup2',right_on='lookup1')\n",
    "    new_df.drop(['lookup1_x', 'lookup2', 'lookup1_y'], axis = 1, inplace = True)\n",
    "    new_df.rename(columns = {points+'_x': points+'_after_race', points+'_y': points}, inplace = True)\n",
    "    new_df[points].fillna(0, inplace = True)\n",
    "    return new_df\n",
    "  \n",
    "driver_standings = lookup(driver_standings, 'driver', 'driver_points')\n",
    "driver_standings = lookup(driver_standings, 'driver', 'driver_wins')\n",
    "driver_standings = lookup(driver_standings, 'driver', 'driver_standings_pos')\n",
    "\n",
    "driver_standings.drop(['driver_points_after_race', 'driver_wins_after_race', 'driver_standings_pos_after_race'], \n",
    "                      axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from year 1990\n",
    "\n",
    "constructor_rounds = rounds\n",
    "\n",
    "constructor_standings = {'season': [],\n",
    "                    'round':[],\n",
    "                    'constructor': [],\n",
    "                    'constructor_points': [],\n",
    "                    'constructor_wins': [],\n",
    "                   'constructor_standings_pos': []}\n",
    "# query API\n",
    "\n",
    "for n in list(range(len(constructor_rounds))):\n",
    "    for i in constructor_rounds[n][1]:\n",
    "    \n",
    "        url = 'https://ergast.com/api/f1/{}/{}/constructorStandings.json'\n",
    "        r = requests.get(url.format(constructor_rounds[n][0], i))\n",
    "        json = r.json()\n",
    "\n",
    "        for item in json['MRData']['StandingsTable']['StandingsLists'][0]['ConstructorStandings']:\n",
    "            try:\n",
    "                constructor_standings['season'].append(int(json['MRData']['StandingsTable']['StandingsLists'][0]['season']))\n",
    "            except:\n",
    "                constructor_standings['season'].append(None)\n",
    "\n",
    "            try:\n",
    "                constructor_standings['round'].append(int(json['MRData']['StandingsTable']['StandingsLists'][0]['round']))\n",
    "            except:\n",
    "                constructor_standings['round'].append(None)\n",
    "                                         \n",
    "            try:\n",
    "                constructor_standings['constructor'].append(item['Constructor']['constructorId'])\n",
    "            except:\n",
    "                constructor_standings['constructor'].append(None)\n",
    "            \n",
    "            try:\n",
    "                constructor_standings['constructor_points'].append(int(item['points']))\n",
    "            except:\n",
    "                constructor_standings['constructor_points'].append(None)\n",
    "            \n",
    "            try:\n",
    "                constructor_standings['constructor_wins'].append(int(item['wins']))\n",
    "            except:\n",
    "                constructor_standings['constructor_wins'].append(None)\n",
    "                \n",
    "            try:\n",
    "                constructor_standings['constructor_standings_pos'].append(int(item['position']))\n",
    "            except:\n",
    "                constructor_standings['constructor_standings_pos'].append(None)\n",
    "            \n",
    "constructor_standings = pd.DataFrame(constructor_standings)\n",
    "\n",
    "constructor_standings = lookup(constructor_standings, 'constructor', 'constructor_points')\n",
    "constructor_standings = lookup(constructor_standings, 'constructor', 'constructor_wins')\n",
    "constructor_standings = lookup(constructor_standings, 'constructor', 'constructor_standings_pos')\n",
    "\n",
    "constructor_standings.drop(['constructor_points_after_race', 'constructor_wins_after_race','constructor_standings_pos_after_race' ],\n",
    "                           axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffcaa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "qualifying_results = pd.DataFrame()\n",
    "\n",
    "for year in list(range(1990,2021)):\n",
    "    url = 'https://www.formula1.com/en/results.html/{}/races.html'\n",
    "    r = requests.get(url.format(year))\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    # find links to all circuits for a certain year\n",
    "    \n",
    "    year_links = []\n",
    "    for page in soup.find_all('a', attrs = {'class':\"resultsarchive-filter-item-link FilterTrigger\"}):\n",
    "        link = page.get('href')\n",
    "        if f'/en/results.html/{year}/races/' in link: \n",
    "            year_links.append(link)\n",
    "    \n",
    "    # for each circuit, switch to the starting grid page and read table\n",
    "\n",
    "    year_df = pd.DataFrame()\n",
    "    new_url = 'https://www.formula1.com{}'\n",
    "    for n, link in list(enumerate(year_links)):\n",
    "        link = link.replace('race-result.html', 'starting-grid.html')\n",
    "        df = pd.read_html(new_url.format(link))\n",
    "        df = df[0]\n",
    "        df['season'] = year\n",
    "        df['round'] = n+1\n",
    "        for col in df:\n",
    "            if 'Unnamed' in col:\n",
    "                df.drop(col, axis = 1, inplace = True)\n",
    "\n",
    "        year_df = pd.concat([year_df, df])\n",
    "\n",
    "    # concatenate all tables from all years  \n",
    "        \n",
    "    qualifying_results = pd.concat([qualifying_results, year_df])\n",
    "\n",
    "# rename columns\n",
    "    \n",
    "qualifying_results.rename(columns = {'Pos': 'grid', 'Driver': 'driver_name', 'Car': 'car',\n",
    "                                     'Time': 'qualifying_time'}, inplace = True)\n",
    "# drop driver number column\n",
    "\n",
    "qualifying_results.drop('No', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f552d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "weather = race.iloc[:,[0,1,2]]\n",
    "\n",
    "info = []\n",
    "\n",
    "# read wikipedia tables\n",
    "\n",
    "for link in race.url:\n",
    "    try:\n",
    "        df = pd.read_html(link)[0]\n",
    "        if 'Weather' in list(df.iloc[:,0]):\n",
    "            n = list(df.iloc[:,0]).index('Weather')\n",
    "            info.append(df.iloc[n,1])\n",
    "        else:\n",
    "            df = pd.read_html(link)[1]\n",
    "            if 'Weather' in list(df.iloc[:,0]):\n",
    "                n = list(df.iloc[:,0]).index('Weather')\n",
    "                info.append(df.iloc[n,1])\n",
    "            else:\n",
    "                df = pd.read_html(link)[2]\n",
    "                if 'Weather' in list(df.iloc[:,0]):\n",
    "                    n = list(df.iloc[:,0]).index('Weather')\n",
    "                    info.append(df.iloc[n,1])\n",
    "                else:\n",
    "                    df = pd.read_html(link)[3]\n",
    "                    if 'Weather' in list(df.iloc[:,0]):\n",
    "                        n = list(df.iloc[:,0]).index('Weather')\n",
    "                        info.append(df.iloc[n,1])\n",
    "                    else:\n",
    "                        driver = webdriver.Chrome()\n",
    "                        driver.get(link)\n",
    "\n",
    "                        # click language button\n",
    "                        button = driver.find_element_by_link_text('Italiano')\n",
    "                        button.click()\n",
    "                        \n",
    "                        # find weather in italian with selenium\n",
    "                        \n",
    "                        clima = driver.find_element_by_xpath('//*[@id=\"mw-content-text\"]/div/table[1]/tbody/tr[9]/td').text\n",
    "                        info.append(clima) \n",
    "                                \n",
    "    except:\n",
    "        info.append('not found')\n",
    "\n",
    "# append column with weather information to dataframe  \n",
    "  \n",
    "weather['weather'] = info\n",
    "\n",
    "# set up a dictionary to convert weather information into keywords\n",
    "\n",
    "weather_dict = {'weather_warm': ['soleggiato', 'clear', 'warm', 'hot', 'sunny', 'fine', 'mild', 'sereno'],\n",
    "               'weather_cold': ['cold', 'fresh', 'chilly', 'cool'],\n",
    "               'weather_dry': ['dry', 'asciutto'],\n",
    "               'weather_wet': ['showers', 'wet', 'rain', 'pioggia', 'damp', 'thunderstorms', 'rainy'],\n",
    "               'weather_cloudy': ['overcast', 'nuvoloso', 'clouds', 'cloudy', 'grey', 'coperto']}\n",
    "\n",
    "# map new df according to weather dictionary\n",
    "\n",
    "weather_df = pd.DataFrame(columns = weather_dict.keys())\n",
    "for col in weather_df:\n",
    "    weather_df[col] = weather['weather'].map(lambda x: 1 if any(i in weather_dict[col] for i in x.lower().split()) else 0)\n",
    "   \n",
    "weather_info = pd.concat([weather, weather_df], axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
